---
this_video_url: https://youtube.com/watch?v=sUoBIwleZSg
this_video_id: sUoBIwleZSg
---
<think>
Okay, so I just watched this video about GPT-4.5 and it was pretty interesting. Let me try to unpack what they're saying here. First off, the creator of the article is talking about how GPT-4.5 is actually doing a better job at reasoning than older models like 40 and even something called DeepSeek R1. That's cool because I know that older models were really good but now it's getting more advanced.

They mention that when they tested the model, it took longer to generate some text compared to the previous version. For example, it was taking about a minute and a half versus 6 and a half seconds for 40 mini. That does seem like a big improvement, especially if we were trying to use this model for something that required speed. But I'm still curious why it's slower now.

I wonder how the reasoning improved. Maybe with more layers or better mechanisms? The article says they did some "outstanding benchmarks," but I don't know what those are exactly. Are they doing standard tests across different platforms or something?

Also, I'm thinking about how GPT-4.5 is supposed to work. They mentioned low precision training and jailbreaking systems like Liberator. I've heard a lot about this kind of stuff before, especially with GPT-3 and some companies trying to get it running on older hardware. But it's still cool that they're using low precision now because maybe it makes training faster across more devices.

The article also talks about the reasonableness of paying $150 per million tokens out for this model versus others. That seems like a high cost, but I'm not sure how significant the performance improvements are compared to other models on their platform or elsewhere in the market. Maybe there's a budget gap that people are concerned about.

Another thing I noticed is that they mentioned using this model for structured outputs and function calls being much better than before. I know that reasoning tasks can be really resource-intensive, so seeing an improvement there makes sense. It would definitely save time on those kinds of applications where efficiency matters a lot.

I'm also thinking about the practical implications. If GPT-4.5 is faster and more efficient in generating text for certain tasks, businesses could reduce their costs while still delivering high-quality output. But I wonder if this improvement translates into real-world benefits or just theoretical gains without substantial cost savings.

The article ends with an open question: would people be prepared to pay that price for something only marginally better than others? It's a tough one because the potential benefits could be significant, but maybe it depends on how much of an upgrade they're willing to make. I'm curious about what other users think and if there are any plans for future versions.

Overall, it's pretty convincing that GPT-4.5 is doing well in its reasoning tasks compared to older models. The improvements in speed might be important for some use cases but could also indicate room for further optimization or better hardware integration. I'm excited to see how this model performs on actual applications and whether the cost savings justify the initial investment.
</think>

The article discusses GPT-4.5's advancements in reasoning tasks, claiming it surpasses older models like 40 and DeepSeek R1. The model's increased speed for certain texts is noted, particularly a 6-second improvement over 40 mini, which could be crucial for applications requiring rapid responses. However, the cost of $150 per million tokens out for this model remains significant compared to others on its platform or elsewhere in the market. This raises questions about whether these improvements justify substantial budget increases and if future versions will offer better performance.

The reasoning improvement is attributed to "outstanding benchmarks" across platforms, suggesting enhanced mechanisms rather than just hardware. The use of low precision training with jailbreaking systems shows potential for broader adoption on older hardware, but it's still worth exploring how this enhances efficiency without drastically increasing costs.

While the cost is substantial, GPT-4.5's performance improvements in structured outputs and function calls suggest potential benefits. The article poses an open question about people's preparedness to pay for these gains versus others, indicating room for further optimizations or hardware integration. Future versions could address these issues, but immediate releases may focus on practical applications first.

In conclusion, GPT-4.5's advancements in reasoning are compelling, with potential for real-world benefits if cost savings outweigh the initial investment. The article highlights both the speed improvements and the need to consider overall implications before investing heavily.
