{
  "code": 200,
  "status": 20000,
  "data": {
    "links": {
      "Skip to main content": "https://fireworks.ai/#main-content",
      "DeepSeek R1": "https://fireworks.ai/models/fireworks/deepseek-r1",
      "Try it now": "https://fireworks.ai/models/fireworks/deepseek-r1/playground",
      "DeepSeek quickstart": "https://docs.fireworks.ai/deepseek/general-deepseek",
      "": "https://www.linkedin.com/company/fireworks-ai/posts/?feedView=all",
      "Model Library": "https://fireworks.ai/models",
      "Docs": "https://docs.fireworks.ai/",
      "Pricing": "https://fireworks.ai/pricing",
      "Blog": "https://fireworks.ai/blog",
      "Contact Us": "https://fireworks.ai/company/contact-us",
      "Careers Join our team and help us build the future of data.": "https://jobs.ashbyhq.com/fireworks.ai",
      "TeamMeet the innovative and driven Fireworks AI team ready to make your project a success.": "https://fireworks.ai/team",
      "PartnersExplore our partnerships and collaborations.": "https://fireworks.ai/partners",
      "FireAttention,": "https://fireworks.ai/blog/fire-attention-serving-open-source-models-4x-faster-than-vllm-by-quantizing-with-no-tradeoffs",
      "Fine-tune": "https://fireworks.ai/blog/fine-tune-launch",
      "FireFunction": "https://fireworks.ai/blog/firefunction-v2-launch-post",
      "on-demand": "https://fireworks.ai/blog/why-gpus-on-demand",
      "Trust Center": "https://trust.fireworks.ai/",
      "Terms": "https://fireworks.ai/terms-of-service",
      "Privacy": "https://fireworks.ai/privacy-policy",
      "Licenses": "https://fireworks.ai/licenses"
    },
    "title": "Fireworks - Fastest Inference for Generative AI",
    "description": "Use state-of-the-art, open-source LLMs and image models at blazing fast speed, or fine-tune and deploy your own at no additional cost with Fireworks AI!",
    "url": "https://fireworks.ai/",
    "content": "Fireworks - Fastest Inference for Generative AI\n=============== \n\n[Skip to main content](https://fireworks.ai/#main-content)\n\n[DeepSeek R1](https://fireworks.ai/models/fireworks/deepseek-r1), a state-of-the-art open model, is now available. [Try it now](https://fireworks.ai/models/fireworks/deepseek-r1/playground) or read our [DeepSeek quickstart](https://docs.fireworks.ai/deepseek/general-deepseek)!\n\n[](https://fireworks.ai/)\n\n*   [Model Library](https://fireworks.ai/models)\n*   [Docs](https://docs.fireworks.ai/)\n*   [Pricing](https://fireworks.ai/pricing)\n*   [Blog](https://fireworks.ai/blog)\n*   [Contact Us](https://fireworks.ai/company/contact-us)\n*   Company\n    \n    *   [Careers Join our team and help us build the future of data.](https://jobs.ashbyhq.com/fireworks.ai)\n    *   [TeamMeet the innovative and driven Fireworks AI team ready to make your project a success.](https://fireworks.ai/team)\n    *   [PartnersExplore our partnerships and collaborations.](https://fireworks.ai/partners)\n\n[](https://discord.gg/fireworks-ai \"Join our Discord for questions and support\")\n\n[](https://fireworks.ai/login)\n\nGo from hype to high-value AIGo from generic to specialized AIGo from single model to compound AIGo from prototype to production AI\n================================================================================================================================\n\n### The fastest and most efficient inference engine to build production-ready, compound AI systems.\n\n[Get Started](https://fireworks.ai/login)\n\n[Talk to an Expert](https://fireworks.ai/company/contact-us)\n\n![Image 1: Graphic](https://fireworks.ai/images/patterns/pattern.svg)\n\nCustomers\n\nTrusted in production\n---------------------\n\n[](https://cursor.sh/ \"Cursor\")[](https://notion.so/ \"Notion\")[](https://doordash.com/ \"Door Dash\")[](https://samsung.com/ \"Samsung\")[](https://uber.com/ \"Uber\")[](https://quora.com/ \"Quora\")[](https://gitlab.com/ \"Gitlab\")[](https://hubspot.com/ \"HubSpot\")[](https://cresta.com/ \"Cresta\")[](https://sourcegraph.com/ \"Sourcegraph\")[](https://upwork.com/ \"Upwork\")[](https://verizon.com/ \"Verizon\")\n\nFireworks AI\n\nWhy Fireworks AI\n----------------\n\n### Bridge the gap between prototype and production to unlock real value from generative AI.\n\n### Designed for speed\n\n*   9x faster RAGFireworks model vs Groq\n*   6x faster image genFireworks SDXL vs other providers on average\n*   1000 tokens/secwith Fireworks speculative decoding\n\n### Optimized for value\n\n*   40x lower cost for chatLlama3 on Fireworks vs GPT4\n*   15x higher throughputFireAttention vs vLLM\n*   4x lower $/tokenMixtral 8x7b on Fireworks on-demand vs vLLM\n\n### Engineered for scale\n\n*   1T+Tokens generated per day\n*   1M+Images generated per day\n*   99.9%uptime for 100+ models\n\nPlatform\n\nFastest platform to build and deploy generative AI\n--------------------------------------------------\n\n### Start with the fastest model APIs, boost performance with cost-efficient customization, and evolve to compound AI systems to build powerful applications.\n\nBlazing fast inference for 100+ models\n--------------------------------------\n\nInstantly run popular and specialized [models](https://fireworks.ai/models), including Llama3, Mixtral, and Stable Diffusion, optimized for peak latency, throughput, and context length. [FireAttention,](https://fireworks.ai/blog/fire-attention-serving-open-source-models-4x-faster-than-vllm-by-quantizing-with-no-tradeoffs) our custom CUDA kernel, serves models four times faster than vLLM without compromising quality.\n\n*   Disaggregated serving\n*   Semantic caching\n*   Speculative decoding\n\n```\nDeepseek R1Meta Llama 3.3Mixtral MoE 8x22bDeepseek V3Stable Diffusion 3F1Qwen 2.5Firefunction V2OpenAI Whisper\n```\n\nFine-tune with Firectl\n\n```\n[data-bright-mode=\"dark\"] { display: block }\nhtml.light [data-bright-mode=\"dark\"] { display: none }\n  [data-bright-theme] ::selection { background-color: var(--selection-background) }\n  \n  firectl create dataset my-dataset path/to/dataset.jsonlfirectl create fine-tuning-job --settings-file path/to/settings.yamlfirectl deploy my-model[data-bright-mode=\"light\"] { display: none }\nhtml.light [data-bright-mode=\"light\"] { display: block }\n  [data-bright-theme] ::selection { background-color: var(--selection-background) }\n  \n  firectl create dataset my-dataset path/to/dataset.jsonlfirectl create fine-tuning-job --settings-file path/to/settings.yamlfirectl deploy my-model\n```\n\nFine-tune and deploy in minutes\n-------------------------------\n\n[Fine-tune](https://fireworks.ai/blog/fine-tune-launch) with our LoRA-based service, twice as cost-efficient as other providers. Instantly deploy and switch between up to 100 fine-tuned models to experiment without extra costs. Serve models at blazing-fast speeds of up to 300 tokens per second on our serverless inference platform.\n\n*   Supervised fine-tuning\n*   Self-tune\n*   Cross-model batching\n\nBuilding blocks for compound AI systems\n---------------------------------------\n\nHandle tasks with multiple models, modalities, and external APIs and data instead of relying on a single model. Use [FireFunction](https://fireworks.ai/blog/firefunction-v2-launch-post), a SOTA function calling model, to compose compound AI systems for RAG, search, and domain-expert copilots for automation, code, math, medicine, and more.\n\n*   Open-weight model\n*   Orchestration and execution\n*   Schema-based constrained generation\n\n```\nFireFunctionFireworks InferenceTextAudioImageEmbeddingMultimodalExternal ToolsDatabaseInternetAPIsKnowledgeGraph\n```\n\nInfrastructure\n\nProduction-grade infrastructure\n-------------------------------\n\n### Build on secure, reliable infrastructure with the latest hardware.\n\nBuilt for developers\n--------------------\n\n*   Start in seconds and pay-per-token with our serverless deployment\n*   Scale with no commitments on dedicated, [on-demand](https://fireworks.ai/blog/why-gpus-on-demand) GPUs\n*   Post-paid pricing with free initial credits\n*   Run on the latest GPUs for blazing speeds\n*   Metrics and team collaboration tools\n\nEnhanced for enterprises\n------------------------\n\n*   Dedicated deployments fully optimized to your use case\n*   Post-paid & bulk use pricing\n*   SOC2 Type II & HIPAA compliant\n*   Unlimited rate limits\n*   Secure VPC & VPN connectivity\n*   BYOC for high QoS\n\nTestimonials\n\nSuccess with Fireworks AI\n-------------------------\n\n*   \"We've had a really great experience working with Fireworks to host open source models, including SDXL, Llama, and Mistral. After migrating one of our models, we noticed a 3x speedup in response time, which made our app feel much more responsive and boosted our engagement metrics.\"\n    \n    Spencer Chan Product Lead - Poe by Quora\n    \n*   \"Fireworks is the best platform out there to serve open source LLMs. We are glad to be partnering up to serve our domain foundation model series Ocean and thanks to its leading infrastructure we are able to serve thousands of LoRA adapters at scale in the most cost effective way.\"\n    \n    Tim Shi CTO - Cresta\n    \n*   \"Fireworks has been a fantastic partner in building AI dev tools at Sourcegraph. Their fast, reliable model inference lets us focus on fine-tuning, AI-powered code search, and deep code context, making Cody the best AI coding assistant. They are responsive and ship at an amazing pace.\"\n    \n    Beyang Liu CTO - SourceGraph\n    \n\nWho we are\n\nBuilt by Experts from Meta's PyTorch Team\n-----------------------------------------\n\nWe handle trillions of inferences daily, ensuring transparency, full model ownership, and complete data privacy—we don't store model inputs or outputs.\n\nServing AI startups, digital-native companies, and Fortune 500 enterprises, we empower disruptors to innovate with new products, experiences, and improved productivity.\n\nWe can't wait to see what you disrupt.\n\n![Image 2: Fireworks team photo](https://fireworks.ai/_next/image?url=%2Fimages%2Fteam%2Ffireworks-team.jpg&w=1920&q=75)\n\n[Get Started](https://fireworks.ai/login)\n\n[See Our Pricing](https://fireworks.ai/pricing)\n\n[](https://fireworks.ai/)\n\n[](https://x.com/FireworksAI_HQ)[](https://www.instagram.com/the.fireworks.ai/)[](https://www.youtube.com/channel/UCHCffBTGYa1Ut72h03ldtGA)[](https://www.linkedin.com/company/fireworks-ai/posts/?feedView=all)[](https://discord.gg/fireworks-ai)\n\n![Image 3: SOC 2 Type 2](https://fireworks.ai/images/compliance/Vanta_Compliance_SOC%202.svg)![Image 4: HIPAA Compliant](https://fireworks.ai/images/compliance/Vanta_Compliance_HIPAA.svg)\n\n© 2024 Fireworks AI, Inc. All rights reserved.\n\nPages\n\n[Home](https://fireworks.ai/)[Pricing](https://fireworks.ai/pricing)[Models](https://fireworks.ai/models)[Docs](https://docs.fireworks.ai/)\n\nCompany\n\n[Blog](https://fireworks.ai/blog)[Careers](https://jobs.ashbyhq.com/fireworks.ai)\n\nLegal\n\n[Trust Center](https://trust.fireworks.ai/)[Terms](https://fireworks.ai/terms-of-service)[Privacy](https://fireworks.ai/privacy-policy)[Licenses](https://fireworks.ai/licenses)",
    "usage": {
      "tokens": 2153
    }
  }
}