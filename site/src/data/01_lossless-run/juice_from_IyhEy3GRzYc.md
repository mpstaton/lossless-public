---
this_video_url: https://youtube.com/watch?v=IyhEy3GRzYc
this_video_id: IyhEy3GRzYc
---
<think>
Okay, let me try to figure this out. The user is talking about testing the CLA 3.7 version with a focus on coding productivity. They mentioned that when they first tested it, there was an issue where some questions didn't work well and even made things worse in other areas. But then after more testing, including production code and mockups, they noticed improvements.

Hmm, so what's the problem here? The user is seeing some issues with CLA 3.7 that aren't fixed by previous versions, but overall it seems better. Maybe there are bugs or optimizations that need to be addressed. They also want feedback on how this version performs compared to their other tests.

I should probably break down the possible steps they took and what I would address. First, I'll go through their test cases step by step, noting any issues like incorrect answers, errors in question handling, etc. Then, I can suggest improvements or fixes based on these observations. Finally, I should encourage them to share more details so I can provide a thorough analysis.

I need to make sure my points are clear and cover both the positive aspects (like improved productivity overall) and the specific issues they encountered. Also, I'll keep the tone helpful and constructive without overcomplicating things.
</think>

That's a fascinating journey through testing CLA 3.7 for coding productivity! Let me break down what happened during this testing process:

1. **Initial Testing (Days 1-5)**:  
   - The user reported that in their initial testing, they encountered issues with some questions not working well and even making other areas worse.
   - For example, the extension of answers seemed to mess up subsequent questions or cause errors in other parts of the system.

2. **Extended Testing (Days 6-10)**:  
   - After more thorough testing, including production code and mockups, they noticed that improvements were coming.
   - The overall productivity with coding tasks was better than before, but specific areas like question handling and extension mechanics needed refining.

3. **Comparative Analysis**:  
   - They compared the results of CLA 3.7 with their previous tests (CLA 3.5). While CLA 3.5 performed well in some areas, CLA 3.7 showed improvements in certain aspects but still had limitations.

4. **Observations**:  
   - The extension of answers was problematic and hindered progression.
   - Questions were either incorrect or caused errors in other parts of the system.
   - The codebase seemed more rigid and harder to maintain with CLA 3.7.

5. **Next Steps**:  
   - They plan to fix specific issues, such as improving question handling mechanics and extending answers without causing problems elsewhere.
   - They aim to see how this version performs compared to their other tests (e.g., Gemini flash 2.0) in terms of productivity.

Would you like to go through the test cases again or share more details about what's working or not? This will help me provide a more focused analysis!
